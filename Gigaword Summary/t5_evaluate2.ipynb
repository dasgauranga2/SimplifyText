{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import T5Model,T5Tokenizer\n",
    "from torch import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Hello', '▁world', '▁how', '▁are', '▁you', '?']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize('Hello world how are you?')\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8774, 296, 149, 33, 25, 58]\n"
     ]
    }
   ],
   "source": [
    "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> </s> <pad> <unk>\n"
     ]
    }
   ],
   "source": [
    "init_token = tokenizer.pad_token\n",
    "eos_token = tokenizer.eos_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0 2\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['t5-small']\n",
    "\n",
    "print(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.t5 = T5Model.from_pretrained('t5-small')\n",
    "        \n",
    "        self.out = nn.Linear(self.t5.config.to_dict()['d_model'],\n",
    "                             self.t5.config.to_dict()['vocab_size'])\n",
    "                \n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        embedded = self.t5(input_ids=src,decoder_input_ids=trg) \n",
    "        \n",
    "        output = self.out(embedded[0])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5Model were not initialized from the model checkpoint at t5-small and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of T5Model were not initialized from the model checkpoint at t5-small and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of T5Model were not initialized from the model checkpoint at t5-small and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of T5Model were not initialized from the model checkpoint at t5-small and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for i in range(4):\n",
    "    new_model = T5Network()\n",
    "    new_model = new_model.half()\n",
    "    new_model.load_state_dict(torch.load(f't5_summ_model_{i+1}.pt'))\n",
    "    models.append(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence2(sentence, eval_model, max_len = 50):\n",
    "    \n",
    "    eval_model.eval()\n",
    "    eval_model = eval_model.float()\n",
    "\n",
    "    src_indexes = [init_token_idx] + sentence + [eos_token_idx]\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0)\n",
    "\n",
    "    trg_indexes = [init_token_idx]\n",
    "\n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            print(src_tensor)\n",
    "            print(src_tensor.shape)\n",
    "            print(trg_tensor)\n",
    "            print(trg_tensor.shape)\n",
    "            print(\"\\n\\n\")\n",
    "            \n",
    "            output = eval_model(src_tensor, trg_tensor)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == eos_token_idx:\n",
    "            break\n",
    "\n",
    "    return trg_indexes[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_summary(txt,test_model):\n",
    "    txt_tokens = tokenizer.tokenize(txt)\n",
    "    txt_ids = tokenizer.convert_tokens_to_ids(txt_tokens)\n",
    "    pred = translate_sentence2(txt_ids,test_model)\n",
    "    pred_tokens = tokenizer.convert_ids_to_tokens(pred)\n",
    "    \n",
    "    return ''.join(pred_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"israeli forces killed two palestinians near the southern west bank town of hebron on wednesday , palestinian hospital officials said .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[0]])\n",
      "torch.Size([1, 1])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[0, 3]])\n",
      "torch.Size([1, 2])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[    0,     3, 30178]])\n",
      "torch.Size([1, 3])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[    0,     3, 30178,    23]])\n",
      "torch.Size([1, 4])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[    0,     3, 30178,    23,  3859]])\n",
      "torch.Size([1, 5])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[    0,     3, 30178,    23,  3859,  5781]])\n",
      "torch.Size([1, 6])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[    0,     3, 30178,    23,  3859,  5781,   192]])\n",
      "torch.Size([1, 7])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[    0,     3, 30178,    23,  3859,  5781,   192,  7692]])\n",
      "torch.Size([1, 8])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[    0,     3, 30178,    23,  3859,  5781,   192,  7692,   222]])\n",
      "torch.Size([1, 9])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[    0,     3, 30178,    23,  3859,  5781,   192,  7692,   222,    77]])\n",
      "torch.Size([1, 10])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[    0,     3, 30178,    23,  3859,  5781,   192,  7692,   222,    77,\n",
      "          7137]])\n",
      "torch.Size([1, 11])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[    0,     3, 30178,    23,  3859,  5781,   192,  7692,   222,    77,\n",
      "          7137,  1084]])\n",
      "torch.Size([1, 12])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[    0,     3, 30178,    23,  3859,  5781,   192,  7692,   222,    77,\n",
      "          7137,  1084,     3]])\n",
      "torch.Size([1, 13])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[    0,     3, 30178,    23,  3859,  5781,   192,  7692,   222,    77,\n",
      "          7137,  1084,     3,    88]])\n",
      "torch.Size([1, 14])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[    0,     3, 30178,    23,  3859,  4792,   192,  7692,   222,    77,\n",
      "          7137,  1084,     8,  7518,  4653,  2137,  1511,    13,     3,    88,\n",
      "         13711,    30,    62,    26,  1496,  1135,     3,     6,  7692,  3340,\n",
      "         15710,  2833,  4298,   243,     3,     5,     1]])\n",
      "torch.Size([1, 37])\n",
      "tensor([[    0,     3, 30178,    23,  3859,  5781,   192,  7692,   222,    77,\n",
      "          7137,  1084,     3,    88, 13711]])\n",
      "torch.Size([1, 15])\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'▁israeli▁forces▁kill▁two▁palestinians▁near▁hebron'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_summary(TEXT,models[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(1, 80).long()\n",
    "y = torch.ones(1, 20).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauranga/anaconda3/envs/pt/lib/python3.8/site-packages/transformers/modeling_utils.py:244: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if causal_mask.shape[1] < attention_mask.shape[1]:\n"
     ]
    }
   ],
   "source": [
    "net_trace = jit.trace(models[3], [x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit.save(net_trace.half(), 't5_ts_summ_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
